{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21eb5e31-f3d8-431a-86c5-c30c97fdaf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, math, json, random, time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Project roots relative to notebooks/\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "DATA_DIR  = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"data\", \"processed\"))\n",
    "MODEL_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"models\"))\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b6605-eb85-4335-9a56-3326df0196e3",
   "metadata": {},
   "source": [
    "## Step 1 — Load, Balance, and Merge Datasets\n",
    "\n",
    "We load processed_LIAR.csv and processed_FakeNews.csv, balance domain sizes, add a source column, and create an 80/10/10 split that is stratified by both label and source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ca7347-188a-48ee-b1bc-855af7232aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source    label\n",
       "FakeNews  0        6033\n",
       "          1        6758\n",
       "LIAR      0        7159\n",
       "          1        5632\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged size: 25582\n",
      "train {'LIAR': 10233, 'FakeNews': 10232} | label {0: 10553, 1: 9912}\n",
      "val {'LIAR': 1279, 'FakeNews': 1279} | label {0: 1319, 1: 1239}\n",
      "test {'FakeNews': 1280, 'LIAR': 1279} | label {0: 1320, 1: 1239}\n",
      "Saved:\n",
      " - /gpfs/home/ashwin/FakeNews-Detection/data/processed/merged_LIAR_FakeNews.csv\n",
      " - /gpfs/home/ashwin/FakeNews-Detection/data/processed/merged_train.csv\n",
      " - /gpfs/home/ashwin/FakeNews-Detection/data/processed/merged_val.csv\n",
      " - /gpfs/home/ashwin/FakeNews-Detection/data/processed/merged_test.csv\n"
     ]
    }
   ],
   "source": [
    "liar_path  = os.path.join(DATA_DIR, \"processed_LIAR.csv\")\n",
    "news_path  = os.path.join(DATA_DIR, \"processed_FakeNews.csv\")\n",
    "\n",
    "assert os.path.exists(liar_path), f\"Missing: {liar_path}\"\n",
    "assert os.path.exists(news_path), f\"Missing: {news_path}\"\n",
    "\n",
    "liar_df = pd.read_csv(liar_path)\n",
    "news_df = pd.read_csv(news_path)\n",
    "\n",
    "# Add 'source' columns\n",
    "liar_df[\"source\"] = \"LIAR\"\n",
    "news_df[\"source\"] = \"FakeNews\"\n",
    "\n",
    "# Balance by domain (upsample smaller domain)\n",
    "target = min(len(liar_df), len(news_df))\n",
    "liar_bal = resample(liar_df, replace=True, n_samples=target, random_state=42)\n",
    "news_bal = resample(news_df, replace=True, n_samples=target, random_state=42)\n",
    "\n",
    "merged = pd.concat([liar_bal, news_bal], ignore_index=True)\n",
    "merged = merged.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "display(merged[[\"source\",\"label\"]].value_counts().sort_index())\n",
    "print(\"Merged size:\", len(merged))\n",
    "\n",
    "# Stratified split by BOTH label and source (composite key)\n",
    "merged[\"strat\"] = merged[\"label\"].astype(str) + \"_\" + merged[\"source\"]\n",
    "train_df, temp_df = train_test_split(\n",
    "    merged, test_size=0.2, stratify=merged[\"strat\"], random_state=42\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df[\"strat\"], random_state=42\n",
    ")\n",
    "\n",
    "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    print(name, df[\"source\"].value_counts().to_dict(), \"| label\", df[\"label\"].value_counts().to_dict())\n",
    "\n",
    "# Persist merged splits (useful for reproducibility and external evaluation)\n",
    "merged_path = os.path.join(DATA_DIR, \"merged_LIAR_FakeNews.csv\")\n",
    "train_path  = os.path.join(DATA_DIR, \"merged_train.csv\")\n",
    "val_path    = os.path.join(DATA_DIR, \"merged_val.csv\")\n",
    "test_path   = os.path.join(DATA_DIR, \"merged_test.csv\")\n",
    "\n",
    "merged.drop(columns=[\"strat\"], errors=\"ignore\").to_csv(merged_path, index=False)\n",
    "train_df.drop(columns=[\"strat\"], errors=\"ignore\").to_csv(train_path, index=False)\n",
    "val_df.drop(columns=[\"strat\"], errors=\"ignore\").to_csv(val_path, index=False)\n",
    "test_df.drop(columns=[\"strat\"], errors=\"ignore\").to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Saved:\", merged_path, train_path, val_path, test_path, sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2cb09a-a0c2-480c-8899-8e4d5c06d172",
   "metadata": {},
   "source": [
    "## Step 2 — Dataset and DataLoader\n",
    "\n",
    "We optionally add a domain tag to each example. For SHAP/LIME later, we will also save raw text copies alongside tensors when needed, but the explainers will use a HF pipeline that expects raw strings, not tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025d47c7-993d-4019-a027-dd6ce67b31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_DOMAIN_TOKEN = True\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, max_len=256, add_domain_token=True, return_text=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len   = max_len\n",
    "        self.return_text = return_text\n",
    "        titles = df[\"title\"].astype(str).tolist()\n",
    "        texts  = df[\"text\"].astype(str).tolist()\n",
    "        srcs   = df[\"source\"].astype(str).tolist()\n",
    "        lbls   = df[\"label\"].astype(int).tolist()\n",
    "        self.labels = lbls\n",
    "        if add_domain_token:\n",
    "            self.strings = [f\"[{s}] {t} {x}\" for s, t, x in zip(srcs, titles, texts)]\n",
    "        else:\n",
    "            self.strings = [f\"{t} {x}\" for t, x in zip(titles, texts)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.strings[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True, padding=\"max_length\", max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        if self.return_text:\n",
    "            item[\"raw_text\"] = self.strings[idx]\n",
    "        return item\n",
    "\n",
    "def build_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, max_len=256, add_domain_token=True):\n",
    "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "    train_ds = NewsDataset(train_df, tokenizer, max_len, add_domain_token)\n",
    "    val_ds   = NewsDataset(val_df,   tokenizer, max_len, add_domain_token)\n",
    "    test_ds  = NewsDataset(test_df,  tokenizer, max_len, add_domain_token)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0, collate_fn=collator)\n",
    "    val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collator)\n",
    "    test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collator)\n",
    "    return train_dl, val_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc5f68-076e-4bb1-88b1-c21b729ca44b",
   "metadata": {},
   "source": [
    "## Step 3 — Model, LoRA, and Label Maps\n",
    "\n",
    "We load RoBERTa, attach LoRA to attention projections, and define label maps. We’ll save these maps so the HF pipeline can display human-readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c21012-8b85-4266-88cd-4c8fe06c0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 125,236,994 || trainable%: 0.4710\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "NUM_LABELS = 2\n",
    "id2label = {0: \"REAL\", 1: \"FAKE\"}\n",
    "label2id = {\"REAL\": 0, \"FAKE\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "model.print_trainable_parameters()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e4adf-eb0e-43a5-826c-60f0f4bf553c",
   "metadata": {},
   "source": [
    "## Step 4 — Hyperparameters and Loaders\n",
    "\n",
    "We define a simple config, build loaders, and create optimizer/scheduler. Mixed precision is enabled automatically later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc18f18-2712-44cc-94e0-2322e5019c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    batch_size: int = 16\n",
    "    max_len: int = 256\n",
    "    lr: float = 5e-5\n",
    "    weight_decay: float = 0.01\n",
    "    epochs: int = 3\n",
    "    warmup_ratio: float = 0.06\n",
    "    grad_accum: int = 1\n",
    "    max_grad_norm: float = 1.0\n",
    "    ckpt_prefix: str = \"roberta_lora_multidomain\"\n",
    "\n",
    "cfg = TrainConfig()\n",
    "\n",
    "train_dl, val_dl, test_dl = build_loaders(\n",
    "    train_df, val_df, test_df, tokenizer,\n",
    "    batch_size=cfg.batch_size, max_len=cfg.max_len,\n",
    "    add_domain_token=ADD_DOMAIN_TOKEN\n",
    ")\n",
    "\n",
    "# Optimizer/scheduler\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dl) / cfg.grad_accum)\n",
    "t_total = cfg.epochs * num_update_steps_per_epoch\n",
    "warmup_steps = int(cfg.warmup_ratio * t_total)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optim,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=t_total\n",
    ")\n",
    "\n",
    "t_total, warmup_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fa667-3b85-4428-b8d3-780ba0b8ffc2",
   "metadata": {},
   "source": [
    "## Step 5 — Train/Eval Loops with Mixed Precision and Early Stopping\n",
    "\n",
    "We train with torch.cuda.amp for speed and stability, evaluate on the val set each epoch, keep the best model by val loss, and rotate step checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47277873-1607-475a-a5b8-c14f1e3cf4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c9a5d6971c4e13a347131078991c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.4209 | val_loss=0.3341 | val_f1=0.7866 | val_acc=0.8151 | time=0.84 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c60dc4cce194650895ff2fc08581deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.3342 | val_loss=0.3229 | val_f1=0.8004 | val_acc=0.8241 | time=0.83 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee68426ac7e4757946571dd63e5ad0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.3279 | val_loss=0.3219 | val_f1=0.8195 | val_acc=0.8335 | time=0.84 min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from torch import amp\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    losses, preds, labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl, desc=\"Evaluating\", leave=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"raw_text\"}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            losses.append(loss.item())\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    loss = float(np.mean(losses))\n",
    "    acc  = accuracy_score(labels, preds)\n",
    "    f1   = f1_score(labels, preds, zero_division=0)\n",
    "    pre  = precision_score(labels, preds, zero_division=0)\n",
    "    rec  = recall_score(labels, preds, zero_division=0)\n",
    "    return {\"loss\": loss, \"acc\": acc, \"f1\": f1, \"precision\": pre, \"recall\": rec}\n",
    "\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "CKPT_BEST_DIR = os.path.join(MODEL_DIR, f\"{cfg.ckpt_prefix}_best\")\n",
    "CKPT_STEP_DIR = os.path.join(MODEL_DIR, f\"{cfg.ckpt_prefix}_steps\")\n",
    "os.makedirs(CKPT_BEST_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_STEP_DIR, exist_ok=True)\n",
    "\n",
    "scaler = amp.GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global_step = 0\n",
    "best_val = float(\"inf\")\n",
    "history = []\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    progress = tqdm(train_dl, desc=f\"Epoch {epoch}/{cfg.epochs}\", leave=True)\n",
    "    for step, batch in enumerate(progress, start=1):\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"raw_text\"}\n",
    "\n",
    "        with amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss / cfg.grad_accum\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if step % cfg.grad_accum == 0:\n",
    "            scaler.unscale_(optim)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "            optim.zero_grad()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / step\n",
    "        progress.set_postfix(loss=f\"{avg_loss:.4f}\", lr=scheduler.get_last_lr()[0])\n",
    "\n",
    "        # Lightweight checkpoint every 1000 steps\n",
    "        if global_step > 0 and global_step % 1000 == 0:\n",
    "            step_path = os.path.join(CKPT_STEP_DIR, f\"step_{global_step}\")\n",
    "            os.makedirs(step_path, exist_ok=True)\n",
    "            model.save_pretrained(step_path)\n",
    "            tokenizer.save_pretrained(step_path)\n",
    "\n",
    "    # End-of-epoch evaluation\n",
    "    epoch_time = (time.time() - epoch_start) / 60\n",
    "    val_metrics = evaluate(model, val_dl)\n",
    "    row = {\"epoch\": epoch,\n",
    "           \"train_loss\": avg_loss,\n",
    "           \"val_loss\": val_metrics[\"loss\"],\n",
    "           \"val_f1\": val_metrics[\"f1\"],\n",
    "           \"val_acc\": val_metrics[\"acc\"],\n",
    "           \"epoch_time_min\": round(epoch_time, 2)}\n",
    "    history.append(row)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={avg_loss:.4f} | val_loss={val_metrics['loss']:.4f} | \"\n",
    "          f\"val_f1={val_metrics['f1']:.4f} | val_acc={val_metrics['acc']:.4f} | \"\n",
    "          f\"time={epoch_time:.2f} min\")\n",
    "\n",
    "    # Save best model by validation loss\n",
    "    if val_metrics[\"loss\"] < best_val:\n",
    "        best_val = val_metrics[\"loss\"]\n",
    "        model.save_pretrained(CKPT_BEST_DIR)\n",
    "        tokenizer.save_pretrained(CKPT_BEST_DIR)\n",
    "        save_json({\"best_val_loss\": best_val, \"epoch\": epoch},\n",
    "                  os.path.join(CKPT_BEST_DIR, \"metrics.json\"))\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(history).to_csv(\n",
    "    os.path.join(MODEL_DIR, f\"{cfg.ckpt_prefix}_history.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
